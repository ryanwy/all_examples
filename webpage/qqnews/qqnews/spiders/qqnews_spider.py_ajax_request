import scrapy
import re

from qqnews.items import qqnewsItem
from scrapy.http import Request
from scrapy.http.request.form import FormRequest

def f1():
    names = []
    import inspect
    frame = inspect.currentframe()
    ## Keep moving to next outer frame
    while True:
        try:
            frame = frame.f_back
            name = frame.f_code.co_name
            names.append(name)
        except:
            break
    return names

def enc(line):
    for l in line:
        print l.encode('utf-8')

class qqnewsSpider(scrapy.Spider):
    name = 'qqnews'
    allowed_domains = ['news.qq.com',
            'coral.qq.com',
        ]
    start_urls = [
        'http://news.qq.com/a/20160427/003825.htm',
    ]

    def parse_ajax(self, response):
        print "HERE **************"
        print response.body
        match = re.search(r"\"commentnum\":\"(\w+)\"\}", response.body)
        self.items['comment_num'] = match.group(1)
        print self.items['comment_num']
        yield self.items

    # 'http://news.qq.com/a/20160531/006521.htm'
    def parse(self, response):
        import traceback
        traceback.print_stack()
        
        item = qqnewsItem()
        self.items = item
        extra_links = ['http://coral.qq.com/article/1383089650/commentnum?callback=_cbSum&source=1&t=0.9233111530535709']
        for url in extra_links:
            yield Request(url, callback = self.parse_ajax )
        
        item['title'] = response.xpath("//div[@class='hd']/h1/text()").extract()
        item['content'] = response.xpath("//div[@id='Cnt-Main-Article-QQ']/p/text()").extract()
        item['msg_src'] = response.xpath("//span[@class='color-a-1']/a[@target='_blank']/text()").extract()
        item['msg_src_link'] = response.xpath("//span[@class='color-a-1']/a[@target='_blank']/@href").extract()
        item['comment_num'] = response.xpath("//div[@class='tit-bar clearfix']/span[@class='r all-number-comment']/a[@id='cmtNum']/text()").extract()
